<?php

/**
 * Collection To Scrape
 *
 * This class represents a collection of resources which
 * are to be scraped. This collection is generated by crawling
 * the supplied URL.
 *
 * Results of the crawl results will be cached to improve
 * performance.
 *
 * Class CollectionToScrape
 */

namespace Scraper;

use FileSystemCache;

class CollectionToScrape {
    /**
     * The URL (resource) which is to be crawled.
     *
     * @var null|string
     */
    public $urlToSpider = null;

    /**
     * Whether to ignore the crawl cache and force a crawl.
     *
     * @var bool
     */
    public $forceSpider = false;

    /**
     * Holds the cache key used to store the crawl results.
     *
     * @var FileSystemCacheKey|null
     */
    protected $cacheKey = null;

    /**
     * Results of crawl process.
     *
     * @var null|array
     */
    public $crawlResults = null;

    /**
     * Class constructor
     *
     * Configure object properties.
     *
     * @param $urlToSpider
     * @param bool|false $forceSpider
     * @param int $crawlDepth
     */
    public function __construct($urlToSpider, $forceSpider = false, $crawlDepth = 3) {
        $this->urlToSpider = $urlToSpider;
        $this->forceSpider = $forceSpider;
        $this->crawlDepth = $crawlDepth;
        $this->cacheKey = FileSystemCache::generateCacheKey([get_class($this), $urlToSpider, $crawlDepth]);
    }

    /**
     * Perform a crawl of the resource.
     */
    protected function crawlResource() {
        $crawler = new \Arachnid\Crawler($this->urlToSpider, $this->crawlDepth);
        $crawler->traverse();
        $this->setCrawlResults($crawler->getLinks());
    }

    /**
     * Get the results of the crawl.
     *
     * @return array|mixed|null
     */
    public function getCrawlResults() {
        if ($this->forceSpider || FileSystemCache::retrieve($this->cacheKey) === false) {
            $this->crawlResource();
            $this->forceSpider = false;
        }

        if (is_null($this->crawlResults)) {
            $this->crawlResults = FileSystemCache::retrieve($this->cacheKey);
        }

        return $this->crawlResults;
    }

    /**
     * Set the results of the crawl.
     *
     * @param $crawlResults
     */
    public function setCrawlResults($crawlResults) {
        $this->crawlResults = $crawlResults;
        FileSystemCache::store($this->cacheKey, $crawlResults);
    }

    public function pagesToScrape() {
        $resources = $this->getCrawlResults();

        // Filter resources to find internal HTML pages
        $resources = array_filter($resources, function($resource) {
            // If $resource['title'] exists, we know this is a HTML page
            // @TODO: This is filtering too many pages? Why is that? See Google Chrome...
            return ( isset($resource['title']) && $resource['external_link'] == false );
        });

        return $resources;
    }
}